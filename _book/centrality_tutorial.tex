\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={An Introduction to Network Centrality},
            pdfauthor={David Schoch},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{An Introduction to Network Centrality}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \subtitle{with Applications in R}
  \author{David Schoch}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2018-12-10}

\usepackage{booktabs}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

\hypertarget{indices}{%
\chapter{Centrality Indices}\label{indices}}

The purpose of network centrality is to identify important actors or
entities in a network. Structural importance is determined by so called
\emph{measures of centrality}, commonly defined in terms of indices
\(c: V \to \mathbb{R}\) interpreted as \[
c(u) > c(v) \iff u \text{ is more central than } v.
\] Since the meaning of structural importance is by no means
unambiguous, a vast amount of different indices have been introduced
over time. In addition, any mapping \(c: V \to \mathbb{R}\) induces a
ranking of nodes, but not every such ranking might represent a plausible
concept of structural importance.

\hypertarget{degree}{%
\section{Degree}\label{degree}}

Degree centrality is the most simple form of a centrality index. It is
defined as \[
c_d(u) = \{v : \{u,v\} \in E\} = \lvert N(u) \rvert
\] Degree centrality is a purely \emph{local} measure since it only
depends on the direct neighborhood of a node. A simple application
example is popularity in friendship networks, i.e. ``who has the most
friends?''. The definition of degree centrality can easily be adapted
for directed and weighted networks. For directed networks, \[
c_d^+(u)=\{v : (u,v) \in E\} = \lvert N^+(u) \rvert \quad \text{and} \quad 
c_d^-(u)=\{v : (v,u) \in E\} = \lvert N^-(u) \rvert
\] are the \emph{out-degree} and \emph{in-degree}, respectively.
\emph{Weighted degree}, sometimes also refered to as \emph{strength}, is
defined as \[
c_{wd}(u)=\sum_{v \in N(u)} w_{uv}.
\]

\hypertarget{betweenness-and-variants}{%
\section{Betweenness (and variants)}\label{betweenness-and-variants}}

Betweenness was independently developed by \citet{a-rdg-71} and
\citet{f-smcbb-77} and is an extension of \emph{stress centrality},
introduced by \citet{s-spcn-53}. Shimbel assumes that the number of
shortest paths containing a node \(u\) is an estimate for the amount of
``stress'' the node has to sustain in a network. The more shortest paths
run through a node the more central it is. Formally, stress centrality
is defined as \[
c_{stress}(u)=\sum\limits_{s,t \in V} \sigma(s,t\lvert u),
\] where \(\sigma(s,t\lvert u)\) is the number of shortest paths from
\(s\) to \(t\) passing through \(u\). Instead of the absolute number of
shortest paths, betweenness centrality quantifies their relative number.
The relative count is given by \[
\delta(s,t\lvert u)= \frac{\sigma(s,t\lvert u)}{\sigma(s,t)},
\] where \(\sigma(s,t)\) is the total number of shortest paths
connecting \(s\) and \(t\). The expression \(\delta(s,t\lvert u)\) can
be interpreted as the extent to which \(u\) controls the communication
between \(s\) and \(t\). Betweenness is then defined as \[
c_b(u) = \sum\limits_{s,t \in V} \delta(s,t\lvert u)
\] The interpretation of betweenness is not only restricted to
communication. More generally, betweenness quantifies the influence of
vertices on the trans- fer of items or information through the network
with the assumption that it follows shortest paths. Many different
variants of shortest path betweenness have been proposed to incorporate
additional assumptions, e.g.~the specific lo- cation of a vertex \(u\)
on a shortest \(s,t\)-path or its length. Some of these variants are
given in the following table.

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
\begin{minipage}[t]{0.81\columnwidth}\raggedright
proximal source\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\(c_{bs}(u) = \sum\limits_{s,t \in V} \delta(s,t\lvert u)\cdot A_{su}\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.81\columnwidth}\raggedright
proximal target\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\(c_{bt}(u) = \sum\limits_{s,t \in V} \delta(s,t\lvert u)\cdot A_{ut}\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.81\columnwidth}\raggedright
k-bounded distance\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\(c_{bk}(u) = \sum\limits_{dist(s,t)\leq k} \delta(s,t\lvert u)\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.81\columnwidth}\raggedright
length-scaled\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\(c_{bd}(u) = \sum\limits_{s,t \in V} \frac{\delta(s,t\lvert u)}{dist(s,t)}\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.81\columnwidth}\raggedright
linearly-scaled\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\(c_{bl}(u) = \sum\limits_{s,t \in V} \delta(s,t\lvert u)\frac{dist(s,u)}{dist(s,t)}\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Details on these variants can be found in \citet{b-vsbctgc-08}. Other
variants of the betweenness concept rely on different assumptions of
transfer in networks besides shortest paths.

A measure based on network flow was defined by \citet{fbw-cvgmbbnf-91}.
The authors assume information as a flow process and assign to each edge
a non-negative value representing the maximum amount of information that
can be passed between the endpoints. The aim is then to measure the
extent to which the maximum flow between two vertices \(s\) and \(t\)
depends on a vertex \(u\). Denote by \(f(s,t)\) the maximum
\((s,t)\)-flow w.r.t. constraints imposed by edge capacities and the
amount of flow which must go through \(u\) by \(f( s, t \lvert u )\) .
Similar to shortest path betweenness, \emph{flow betweenness} is then
defined as \[
c_f(u)=\sum\limits_{s,t \in V} \frac{f(s,t\lvert u)}{f(s,t)}.
\] The index was introduced as a betweenness variant for weighted
networks but it can easily applied to unweighted ones. In the case of
simple undirected and unweighted networks, the maximum \((s, t)\)-flow
is equivalent to the number of edge disjoint \((s,t)\)-paths and
\(f(s,t|u)\) is the number of paths \(u\) lies on.

A variant based on walks instead of paths was proposed by
\citet{n-mbcbrw-05}. His \emph{random walk betweenness} calculates the
expected number of times a random \((s,t)\)-walk passes through a vertex
\(u\), averaged over all \(s\) and \(t\). Newman shows, that his variant
of betweenness can also be calculated with a current-flow analogy by
viewing a graph as an electrical network. Random walk betweenness is
then equiva- lent to the amount of current that flows through \(u\). The
index is thus also known as \emph{current flow betweenness}. Details and
formal definitions of his versions can be found in the literature
\citep{n-mbcbrw-05, bf-cmbcf-05}.

Two variants based on the \emph{randomzed shortest path} (RSP) framework
\citep{ysms-fdmngbscd-08, safy-rsptrm-09, kss-dtrspcgnd-14} were
proposed by \citet{klss-tbcmbrsp-16}. The variants are refered to as
\emph{simple RSP betweenness} and \emph{RSP net betweenness}. The
derivation of both indices is rather involved and goes beyond the scope
of this tutorial. The interested reader should consult the original work
for details. One aspect worth mentioning, though, is that both variants
include a tuning parameter \(\beta\). Both variants converge to the
traditional version of betweennes for \(\beta \to \infty\). For
\(\beta \to 0\), simple RSP betweenness converges to the expected number
of visits to a node over all absorbing walks with respect to the
unbiased random walk probabilities. This means for undirected networks,
that the index converges to degree. RSP net betweenness, on the other
hand, converges to Newmann's random walk betweenness.

All variants of betweenness can be described in a more general form
considering a flow of information analogy. Depending on the assumption
of how information is `flowing' between \(s\) and \(t\), the set
\(P(s, t)\) contains all possible information channels to transmit the
piece of information. This set might contain all shortest
\(( s, t )\)-paths if the information has to be trans- mitted as fast as
possible or all random \((s, t)\)-walks when the delivery time does not
matter. In principle, any kind of trajectory on a graph can be thought
of as an information channel. The set \(P( s, t \lvert u )\) contains
all information channels where the vertex \(u\) is in a position to
control the information flow. For shortest path betweenness, \(u\) is in
a controlling position if it is part of an information channel and for
proximal target betweenness if it presents the information to the target
\(t\). In the former case \(P( s, t \lvert u )\) comprises all elements
of \(P(s, t)\) that contain \(u\) as an intermediary and in the latter
all elements that contain the edge \((u,t)\) . Again, the position of
control could be defined as any location on a trajectory. A measure of
relative betweenness is then defined with aggregation rules over the two
specified sets, commonly the fraction of their cardinalities. This
fraction can also be weighted according to specified rules, e.g.~as in
length scaled betweenness. Aggregating over all possible sources and
targets, we can thus define a \emph{generic betweenness} index as \[
c_{bg}(u) = \sum\limits_{s,t \in V}\frac{\lvert P(s,t\lvert u) \rvert}{\lvert P(s,t) \rvert} \cdot w(s,t).
\] Thus, many other variants are possible, for instance also
\(k\)-betweenness mentioned by \citet{be-gpc-06}, where \(P( s, t )\) is
the set of all \(( s, t )\)-paths of length at most \(k\).

There exist many more betweenness-like indices that where not covered
here, but are listed below in no particular order:

\begin{itemize}
\tightlist
\item
  \emph{communicability betweenness} based on the matrix exponential
  \citep{ehh-cbcn-09}
\item
  \(\alpha\) and \(\beta\) betweenness, which are closely related to
  current flow betweenness \citep{alms-acfbc-13, amt-bcfcwn-15},
\item
  \emph{ranking betweenness}, which combines betweenness with the idea
  of PageRank \citep{aotv-nbcmbarnn-14}
\item
  range-limited forms of betweenness \citep{elct-rcmcn-12}
\item
  \emph{bridgeness} \citep{jmkvvjcmf-dgbn-16}
\item
  \emph{super mediator} \citep{skom-sm-ncmniidsn-16}
\item
  \emph{BridgeRank} \citep{sam-bnfcmblsn-18}
\end{itemize}

\hypertarget{closeness-and-variants}{%
\section{Closeness (and variants)}\label{closeness-and-variants}}

Closeness centrality was first mentioned by \citet{b-cptg-50} and later
formally defined by \citet{s-cig-66}. Closeness is defined as the
reciprocal of the sum of distances from a node to all other nodes in the
network, that is \[
c_c(u)=\frac{1}{\sum\limits_{t \in V} dist(u,t)}.
\] Vertices in a network are considered to be central if they have a
small total distance to all other vertices in the network. By definition
of graph-theoretic distances, closeness is ill-defined on unconnected
graphs. A close variant ap- plicable to both connected and unconnected
graphs is given by \[
c_{hc}(u)=\sum\limits_{t \in V}\frac{1}{dist(u,t)}.
\] This variant was proposed by various researcher. Among the first are
\citet{gs-pnm-96} who refer to it as \emph{power index}.
\citet{r-cceughci-09} later introduced it as \emph{harmonic closeness}.

As in the case of betweenness, many different variations of closeness
have been proposed, mostly to correct for the fact that the
``classical'' closeness is not properly defined on unconnected networks.
\citet{mm-dpusn-74} introduced an index which penalizes the number of
not reachable nodes. Their \emph{adjusted index of centrality} is
defined as

\[
c_{aic}(u) = \frac{\sum_{s \in V}\sum_{t \in V} dist(s,t)+\rho n_s}{\sum_{t \in V} dist(u,t)+\rho n_u},
\] where \(n_u\) are the number of non-reachable nodes by \(u\) and
\(\rho\) is a penalizing factor.

vf-irmeicrn-98 introduce \emph{integration} as an index which evaluates
how well a vertex is integrated in a network. It is defined as \[
c_{int}(u)=\frac{\sum_{t \in V} (diam(G)+1-dist(u,t))}{n-1},
\] where \(diam(G)\) is the diameter of the network.

\citet{d-rcn-06} suggests \[
c_{rc}=\sum_{t \in V} \frac{1}{2^{dist(u,t)}}
\] as another variant.

There also exist at least two parametrized versions of closeness.
\citet{j-sen-10} introduced \emph{decay centrality} as \[
c_{dc}= \sum_{t \in V} \alpha^{dist(u,t)}
\] where \(\alpha \in (0,1)\). \emph{Generalized closeness}, proposed by
\citet{abe-gbculg-17}, is parametrized in a slightly different way.
Formally, \[
c_{gc}(u)=\sum_{t \in V} dist(u,t)^{-\alpha},
\] where \(\alpha\geq0\). The index apporaches classic closeness for
\(\alpha \to 1\) and converges to degree for \(\alpha \to \infty\).

\citet{hh-ecn-95} introduced \emph{eccentricity}, which does not rely on
summing up all distances, but simply taking the inverse of the maximum,
that is \[
c_{ec}=\frac{1}{\max\{dist(u,t): t\in V\}}.
\]

While distances in networks are commonly defined via shortest paths,
other concepts, such as \emph{random walks} \citep{nr-rwcn-04}, have
also been used to design closeness-like indices. An index of particular
interest is \emph{information centrality}, proposed by
\citet{sz-rcme-89}. The index is based on counting all paths between two
vertices and the edge overlap among these paths. Afterwards, a matrix is
formed that contains the lengths of all paths on the diagonal and the
overlap on the off diagonal entries. This matrix is inverted and a
harmonic mean of each row is formed. The authors interpret this
procedure from an information-theoretic point view. They argue that the
information content of a path is inversely propor- tional to the length
of a path and the edge overlap represents a covariance among paths. Note
that these calculations do not have to be performed explicitly but can
be derived by inverting a matrix \[
C = ( L + J )^{−1},
\] where \(L\) is the Laplacian matrix and \(J\) the matrix of all ones.
With the matrix \(C\), information centrality equates to

\[
c_{inf}(u)=\left(C_{uu}+ \frac{T-2R}{n}\right)^{-1},
\] where \[
T=\sum\limits_{v \in V} C_{vv} \quad \text{ and } \quad R=\sum\limits_{v \in V} C_{uv}.
\] Note that \(T\) and \(R\) are the same for all vertices, such that
the induced ranking only depends on \(C_uu\).

\hypertarget{eigenvector-and-variants}{%
\section{Eigenvector (and variants)}\label{eigenvector-and-variants}}

Eigenvector centrality was introduced by \citet{b-fwassci-72}, yet
earlier versions can already be found in \citet{w-afrt-52} and
\citet{b-tgsa-58}. The index is part of the class of \emph{feedback
centralities}. Measures in this class assume that the centrality of a
node is conditional on the centrality of its neighbors. Nodes are highly
central if they are connected to other highly central nodes. If we
define the centrality of a vertex as the sum of the centrality scores of
its adjacent vertices, we obtain \[
c_e(u)=\sum_{t \in V} A_{ut}c_e(u).
\] The resulting system of equation by considering the eigenvalue
problem \(\lambda_1 x=Ax\). eigenvector centrality is then given by the
eigenvector \(x_1\) associated with the principal eigenvalue
\(\lambda_1\). Note that the principal eigenvector can also be computed
with the power iteration by repeatedly multiplying \(A\) to an arbitrary
vector \(b_0\) until convergence, i.e. \[
\lim\limits_{k \to \infty}\frac{A^kb_0}{\| A^kb_0 \|}=x_1
\] Since an entry \(A^k_{uv}\) is the number of \((u,v)\)-walks of
length \(k\), eigenvector centrality of a node \(u\) can also be seen as
the limit proportion of walks starting at \(u\).

Google's \emph{PageRank} is undoubtedly one of the most famous
adaptations of eigenvector centrality for directed graphs
\citep{pbmw-pcrbow-99}. It is defined as \[
c_{pr}(u)=\sum\limits_{v \in N^-(u)} \alpha \frac{c_{pr}(v)}{c_d^+(v)}+ (1-\alpha)
\] where \(\alpha\) is damping factor, commonly set to \(0.85\). Note
that an equivalent index was already introduced earlier by
\citet{fj-sio-90} (see \citet{fj-tso-14} for a discussion).

A feedback centrality dating back to 1953 was introduced by
\citet{k-nsidsa-53}. Similarly to eigenvector centrality, all walks
emanating from a node \(u\) are summed up but longer walks are penalized
by an attenuation factor \(\alpha\). For- mally, \emph{Katz status} is
defined as \[
c_{katz}(u)=\sum\limits_{k=0}^\infty \sum_{t \in V} \alpha^k A^k_{ut}.
\] In order for the series to converge, \(\alpha\) has to be chosen such
that it is smaller than the reciprocal of the largest eigenvalue of
\(A\). In this case, Katz status can be calculated with the closed form
\[
c_{katz}(u)=\left( (I-\alpha A)^{-1}\cdot \boldsymbol{1}_n\right)_u,
\] where \(\boldsymbol{1}_n\) is the all one vector of length \(n\). A
close variant is Bonacich's \(\beta\)-centrality, whose definition also
allows for a negative attenuation factor \(\beta\) \citep{b-fwassci-72}.
It is given by \[
c_{\alpha,\beta}(u) = \alpha\sum\limits_{k=1}^\infty \sum_{t \in V} \beta^k A^{k-1}_{ut},
\] where \(\alpha\) is merely a scaling factor, such that it can be
omitted without altering the induced ranking. With
\(|\beta| \leq \frac{1}{\lambda_1}\), a closed form is given by \[
c_{\alpha,\beta}(u) = \left((I-\beta A)^{-1}A \cdot \boldsymbol{1}_n\right)_u.
\] Katz status and eigenvector centrality can be considered as positive
feedback centralities, since the centrality of a vertex is higher if it
is connected to other vertices with a high centrality score. In
contrast, Bonacich's β-centrality with a negative β is a negative
feedback centrality, since vertices are considered central, if they are
connected to vertices with low centrality score. This kind of centrality
is particularly of interest in bargaining situations since bargaining
power comes from being in a better position than negotiating partners.

\hypertarget{matrix-exponential}{%
\section{Matrix exponential}\label{matrix-exponential}}

There exist a variety of indices which are based on the matrix
exponential \(\exp(A)\) of the adjacency matrix. The first of this kind,
\emph{subgraph centrality}, was introduced by \citet{er-sccn-05}. It is
closely related to eigenvector centrality and Katz status, since it also
involves counting walks. The difference is that only closed walks are
considered and longer walks are inversely weighted by the factorial of
their length, i.e. \[
c_s(u)=\sum_{k=0}^\infty\frac{A^k_{uu}}{k!}.
\] The weighting by factorials is a convenient choice since it
guarantees conver- gence of the series. Its closed form is given by the
matrix exponential, such that \[
c_s(u)=\exp(A)_{uu}.
\] The authors also consider variants, where only walks of even or odd
length are considered, giving rise to \emph{even} and \emph{odd subgraph
centrality} defined as \[
c_{se}(u)=\sum_{k=0}^\infty\frac{A^{2k}_{uu}}{(2k)!} \quad \text{and} \quad c_{so}(u)=\sum_{k=0}^\infty\frac{A^{2k+1}_{uu}}{(2k+1)!}.
\] All three indices can also be expressed with the spectral
decomposition of \(A\): \[
  c_s(u)=\sum_{k=0}^n \exp(\lambda_j) x_j^2(u)
\] \[
  c_{se}(u)=\sum_{k=0}^n \cosh(\lambda_j) x_j^2(u)
\] \[
  c_{so}(u)=\sum_{k=0}^n \sinh(\lambda_j) x_j^2(u),
\] where \(x_j(u)\) is the \(u\)th entry of the eigenvector \(x_j\)
associated with the eigen- value \(\lambda_j\).

\hypertarget{others}{%
\section{Others}\label{others}}

\hypertarget{references}{%
\section{References}\label{references}}

\bibliography{Indices.bib,Theory.bib}


\end{document}
